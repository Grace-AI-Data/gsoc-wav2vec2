{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('t5': conda)"
    },
    "interpreter": {
      "hash": "184c0bf4d405d4a36e719b504ff2a22c838d19108535bf816dff1a5aad495b87"
    },
    "colab": {
      "name": "wav2vec2-base-saved-model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasudevgupta7/gsoc-wav2vec2/blob/export/notebooks/wav2vec2-base-saved-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndG8MjmJeicp"
      },
      "source": [
        "# How to train TensorFlow saved-model with extra head\n",
        "\n",
        "In this notebook, we will load pre-trained wav2vec2 model from TFHub and will train it on librispeech dataset by appending one extra head over the top of our pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWk8nL6Ui-_0"
      },
      "source": [
        "## Setting Up\n",
        "\n",
        "Before diving into it, let's see what GPU we got using `nvidia-smi`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2DQV2hde_Vh",
        "outputId": "2a490fc5-cf37-4dbd-da00-7fbb2c6306c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul 17 12:41:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hBGUWT_mKkw"
      },
      "source": [
        "Following cell will clone the code repositary and will install all the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seqTlMyeZvM4",
        "outputId": "e1b14e4a-9273-4929-9480-070e730680cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/vasudevgupta7/gsoc-wav2vec2 --branch=export\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "os.chdir(\"gsoc-wav2vec2\")\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "!pip3 install -qe ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gsoc-wav2vec2' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFQDM1t8Z_XK",
        "outputId": "718d809f-d095-4586-8383-bda1beee0e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This cell will be removed after model get exported to TFHub\n",
        "!wget https://huggingface.co/vasudevgupta/tf-wav2vec2-base/resolve/main/wav2vec2-base.tar.gz\n",
        "!tar -xf wav2vec2-base.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 12:41:35--  https://huggingface.co/vasudevgupta/tf-wav2vec2-base/resolve/main/wav2vec2-base.tar.gz\n",
            "Resolving huggingface.co (huggingface.co)... 15.197.130.34\n",
            "Connecting to huggingface.co (huggingface.co)|15.197.130.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/vasudevgupta/tf-wav2vec2-base/ba29ac5ff1f78271a6c9e6466cedd221e811b5ed58020337d238bc14512de9f3 [following]\n",
            "--2021-07-17 12:41:35--  https://cdn-lfs.huggingface.co/vasudevgupta/tf-wav2vec2-base/ba29ac5ff1f78271a6c9e6466cedd221e811b5ed58020337d238bc14512de9f3\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.85.144.69, 52.85.144.70, 52.85.144.56, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.85.144.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 387426816 (369M) [application/octet-stream]\n",
            "Saving to: ‘wav2vec2-base.tar.gz.1’\n",
            "\n",
            "wav2vec2-base.tar.g 100%[===================>] 369.48M  37.5MB/s    in 9.3s    \n",
            "\n",
            "2021-07-17 12:41:44 (39.9 MB/s) - ‘wav2vec2-base.tar.gz.1’ saved [387426816/387426816]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3_fgx4eZvM7",
        "outputId": "40fa6386-a2fc-478e-a42c-b2275ac8ce22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from wav2vec2 import Wav2Vec2Config, CTCLoss\n",
        "\n",
        "config = Wav2Vec2Config()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_5cjb_EZvM8",
        "outputId": "499f46e3-3feb-4ead-c0de-5fa6f637e5f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: update it to load from TFHub later\n",
        "loaded = hub.load(\"saved-model\")\n",
        "print(\"Available signatures are:\", list(loaded.signatures.keys()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available signatures are: ['infer', 'train']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO6QRC7KZvM9"
      },
      "source": [
        "pretrained_model = loaded.signatures[\"train\"]\n",
        "pretrained_model = hub.KerasLayer(pretrained_model, trainable=False)\n",
        "\n",
        "lm_head = tf.keras.layers.Dense(config.vocab_size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f5M8YXXZvM_"
      },
      "source": [
        "@tf.function(jit_compile=True)\n",
        "def forward(batch):\n",
        "    return lm_head(pretrained_model(batch)[\"output_0\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_OWtO4uZvM-"
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "LEARNING_RATE = 5e-5\n",
        "AUDIO_MAXLEN = 246000"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgL5wyaXZvM-",
        "outputId": "5b6b37bc-836d-4dbb-b94d-70cd4a58a033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "forward(tf.random.uniform(shape=(BATCH_SIZE, AUDIO_MAXLEN)))\n",
        "print(\"Number of trainable variables:\", len(list(pretrained_model.trainable_variables) + lm_head.trainable_variables))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable variables: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glDepVEHZvM_"
      },
      "source": [
        "loss_fn = CTCLoss(config, (BATCH_SIZE, AUDIO_MAXLEN), division_factor=BATCH_SIZE)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kIEC77cBCM",
        "outputId": "f5a2a8a2-a0a0-41df-b4a4-4df480c3c297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://huggingface.co/datasets/vasudevgupta/gsoc-librispeech/resolve/main/train-clean-100/train-clean-100-0.tfrecord -P /content/gsoc-wav2vec2/data/train/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 12:42:20--  https://huggingface.co/datasets/vasudevgupta/gsoc-librispeech/resolve/main/train-clean-100/train-clean-100-0.tfrecord\n",
            "Resolving huggingface.co (huggingface.co)... 15.197.130.34\n",
            "Connecting to huggingface.co (huggingface.co)|15.197.130.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/datasets/vasudevgupta/gsoc-librispeech/df6dfb983f6514a98fc05d2ee219f57b1286589d61c1271bb10a0ed3effd6ae8 [following]\n",
            "--2021-07-17 12:42:20--  https://cdn-lfs.huggingface.co/datasets/vasudevgupta/gsoc-librispeech/df6dfb983f6514a98fc05d2ee219f57b1286589d61c1271bb10a0ed3effd6ae8\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.85.132.4, 52.85.132.34, 52.85.132.50, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.85.132.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 483730930 (461M) [application/octet-stream]\n",
            "Saving to: ‘/content/gsoc-wav2vec2/data/train/train-clean-100-0.tfrecord.1’\n",
            "\n",
            "train-clean-100-0.t 100%[===================>] 461.32M  44.8MB/s    in 8.0s    \n",
            "\n",
            "2021-07-17 12:42:28 (57.5 MB/s) - ‘/content/gsoc-wav2vec2/data/train/train-clean-100-0.tfrecord.1’ saved [483730930/483730930]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbBpo74BcUuI",
        "outputId": "69d4c6f1-3746-4d48-d923-223d76eaaa33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls /content/gsoc-wav2vec2/data/train/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train-clean-100-0.tfrecord  train-clean-100-0.tfrecord.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m1Bryfocmm2",
        "outputId": "2e1068b2-f710-4978-ab12-a2d45a0937e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/      \u001b[01;34mnotebooks\u001b[0m/        \u001b[01;34msaved-model\u001b[0m/  \u001b[01;34msrc\u001b[0m/        wav2vec2-base.tar.gz\n",
            "\u001b[01;34mdata\u001b[0m/        readme.md         setup.cfg     \u001b[01;34mtests\u001b[0m/      wav2vec2-base.tar.gz.1\n",
            "LICENSE.txt  requirements.txt  setup.py      vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkIu_Wt4ZvNA",
        "outputId": "878878d1-534a-4133-9381-12ab40887a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import LibriSpeechDataLoaderArgs, LibriSpeechDataLoader\n",
        "\n",
        "data_args = LibriSpeechDataLoaderArgs(\n",
        "    from_tfrecords=True,\n",
        "    tfrecords=[\"data/train/train-clean-100-0.tfrecord\"],\n",
        "    audio_maxlen=AUDIO_MAXLEN,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "dataloader = LibriSpeechDataLoader(data_args)\n",
        "dataset = dataloader(seed=None)\n",
        "\n",
        "num_batches = 2\n",
        "dataset = dataset.take(num_batches)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading `vocab.json` from https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/vocab.json ... DONE\n",
            "Reading tfrecords from ['data/train/train-clean-100-0.tfrecord'] ... Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RYI8ra_ZvNA"
      },
      "source": [
        "@tf.function\n",
        "def train_step(speech, labels):\n",
        "    with tf.GradientTape() as gtape:\n",
        "        speech = forward(speech)\n",
        "        loss = loss_fn(labels, speech)\n",
        "    trainable_variables = list(pretrained_model.trainable_variables) + lm_head.trainable_variables\n",
        "    grads = gtape.gradient(loss, trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUujvZn4ZvNA"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "pbar = tqdm(dataset, total=num_batches)\n",
        "for speech, label in pbar:\n",
        "    loss = train_step(speech, label)\n",
        "    pbar.set_postfix(tr_loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWXWc7CZvNB"
      },
      "source": [
        "@tf.function\n",
        "def eval_step(speech, labels):\n",
        "    speech = forward(speech)\n",
        "    loss = loss_fn(labels, speech)\n",
        "    return loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTFVjZghckJ"
      },
      "source": [
        "pbar = tqdm(dataset, total=num_batches)\n",
        "for speech, label in pbar:\n",
        "    loss = eval_step(speech, label)\n",
        "    pbar.set_postfix(val_loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCxfNFFVh9LR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}