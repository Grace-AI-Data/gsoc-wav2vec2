{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "07c4df7ea0886a603057dcbd29d886eaa26a0122c4b0c39e2937eba8f7497417"
    },
    "colab": {
      "name": "librispeech-evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasudevgupta7/gsoc-wav2vec2/blob/patch-4/notebooks/librispeech-evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd7-lI7dKOq5"
      },
      "source": [
        "# Wav2Vec2 inference on LibriSpeech dataset\n",
        "\n",
        "In this notebook, we will be evaluating TensorFlow Wav2Vec2 using the checkpoint fine-tuned on 960h of LibriSpeech dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiX2ysgINHgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08981ea9-9211-433a-c53c-7359bb7481d1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 23 15:27:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYQDmBpAKooQ"
      },
      "source": [
        "Let's start with basic setup and install `wav2vec2` package from this [repositary](https://github.com/vasudevgupta7/gsoc-wav2vec2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPdD2NGamaGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3281bf-7312-4045-9972-ccda378c3ab2"
      },
      "source": [
        "!git clone https://github.com/vasudevgupta7/gsoc-wav2vec2 --branch=main && cd gsoc-wav2vec2 && pip3 install .\n",
        "\n",
        "import os\n",
        "os.chdir(\"./gsoc-wav2vec2/src\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gsoc-wav2vec2'...\n",
            "remote: Enumerating objects: 430, done.\u001b[K\n",
            "remote: Counting objects: 100% (430/430), done.\u001b[K\n",
            "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
            "remote: Total 430 (delta 249), reused 343 (delta 173), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (430/430), 380.84 KiB | 2.00 MiB/s, done.\n",
            "Resolving deltas: 100% (249/249), done.\n",
            "Processing /content/gsoc-wav2vec2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from wav2vec2==0.0.1) (2.5.0)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/b4/9d92953d8cddc8450c859be12e3dbdd4c7754fb8def94c28b3b351c6ee4e/wandb-0.10.32-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 8.6MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/45/94/27f4f66d8d763f60204f447287cbe78d8bdf9c86d87dbc1fe26e792e727a/huggingface_hub-0.0.11-py3-none-any.whl\n",
            "Collecting tensorflow_io\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/d2/6fd39a3519e325037462721092248b468ccbeeeb5dc870cea072655ee4b0/tensorflow_io-0.18.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1MB 115kB/s \n",
            "\u001b[?25hCollecting jiwer\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/cc/fb9d3132cba1f6d393b7d5a9398d9d4c8fc033bc54668cf87e9b197a6d7a/jiwer-2.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from wav2vec2==0.0.1) (2.7.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->wav2vec2==0.0.1) (1.34.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->wav2vec2==0.0.1) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 37.1MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.0MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->wav2vec2==0.0.1) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->wav2vec2==0.0.1) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->wav2vec2==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->wav2vec2==0.0.1) (4.41.1)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/37/6cedfcc52f1d53a79a60204fc89d1f7ca099c5d3a999d4640a2fe407e91b/tensorflow_io_gcs_filesystem-0.18.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 37.8MB/s \n",
            "\u001b[?25hCollecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->wav2vec2==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (1.31.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->wav2vec2==0.0.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->wav2vec2==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->wav2vec2==0.0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->wav2vec2==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->wav2vec2==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface-hub->wav2vec2==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (1.3.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->wav2vec2==0.0.1) (3.1.1)\n",
            "Building wheels for collected packages: wav2vec2, pathtools, subprocess32, python-Levenshtein\n",
            "  Building wheel for wav2vec2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wav2vec2: filename=wav2vec2-0.0.1-cp37-none-any.whl size=18186 sha256=0a70be3ca51762bccd39c6164dcb9de4dfd076b6ff7a06fad76b5698c8486d17\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/e0/d1/2ff27c3e98bf55e0ea6a95e9b1a41165d4aa5c42a71cb92c86\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=cc94259b29144ba338f7e17d06363ec803e181528963d0c6eb01a69856c2ec22\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=24e7396f005bad8b6d0ba0375f7b085e8af3ab684a4ebdeedd8b94faa4013728\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149827 sha256=efbe5b52d640ec626a1f2d63b9c319d72b25557ed8abd05fb087d40b4b07bf04\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built wav2vec2 pathtools subprocess32 python-Levenshtein\n",
            "Installing collected packages: smmap, gitdb, GitPython, pathtools, shortuuid, configparser, sentry-sdk, subprocess32, docker-pycreds, wandb, huggingface-hub, tensorflow-io-gcs-filesystem, tensorflow-io, python-Levenshtein, jiwer, wav2vec2\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 huggingface-hub-0.0.11 jiwer-2.2.0 pathtools-0.1.2 python-Levenshtein-0.12.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 tensorflow-io-0.18.0 tensorflow-io-gcs-filesystem-0.18.0 wandb-0.10.32 wav2vec2-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxtei0QnK-54"
      },
      "source": [
        "Now that we have installed required packages, lets download validation dataset from official LibriSpeech [website](https://www.openslr.org/12). It may take couple of seconds depending on your internet connection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB1YPH5osJnh",
        "outputId": "4a97a3ca-38ba-45f8-e893-5fd347ab233f"
      },
      "source": [
        "!wget https://www.openslr.org/resources/12/test-clean.tar.gz -P /content/gsoc-wav2vec2/data && tar -xf /content/gsoc-wav2vec2/data/test-clean.tar.gz -C /content/gsoc-wav2vec2/data/\n",
        "!wget https://www.openslr.org/resources/12/test-other.tar.gz -P /content/gsoc-wav2vec2/data && tar -xf /content/gsoc-wav2vec2/data/test-other.tar.gz -C /content/gsoc-wav2vec2/data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-23 15:27:19--  https://www.openslr.org/resources/12/test-clean.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 346663984 (331M) [application/x-gzip]\n",
            "Saving to: ‘/content/gsoc-wav2vec2/data/test-clean.tar.gz’\n",
            "\n",
            "test-clean.tar.gz   100%[===================>] 330.60M  19.0MB/s    in 18s     \n",
            "\n",
            "2021-06-23 15:27:38 (17.9 MB/s) - ‘/content/gsoc-wav2vec2/data/test-clean.tar.gz’ saved [346663984/346663984]\n",
            "\n",
            "--2021-06-23 15:27:41--  https://www.openslr.org/resources/12/test-other.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 328757843 (314M) [application/x-gzip]\n",
            "Saving to: ‘/content/gsoc-wav2vec2/data/test-other.tar.gz’\n",
            "\n",
            "test-other.tar.gz   100%[===================>] 313.53M  20.1MB/s    in 17s     \n",
            "\n",
            "2021-06-23 15:27:58 (18.8 MB/s) - ‘/content/gsoc-wav2vec2/data/test-other.tar.gz’ saved [328757843/328757843]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXCLRAnkLk-K"
      },
      "source": [
        "Let's import `Wav2Vec2Processor` and `Wav2Vec2ForCTC` from our installed `wav2vec2` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOU27UIXmI6o"
      },
      "source": [
        "import tensorflow as tf\n",
        "from wav2vec2 import Wav2Vec2Processor, Wav2Vec2ForCTC"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-2ofEizLz6U"
      },
      "source": [
        "Now, we will instantiate all the classes from their default configurations. Convenient `.from_pretrained(...)` method will enable us to download pre-trained/fine-tuned weights automatically from HuggingFace Hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCzxKNWlmI6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5e8ed0-7068-45bf-9d02-7b83d15309cb"
      },
      "source": [
        "model_id = \"vasudevgupta/tf-wav2vec2-base-960h\"\n",
        "\n",
        "processor = Wav2Vec2Processor(is_tokenizer=False)\n",
        "tokenizer = Wav2Vec2Processor(is_tokenizer=True)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading model weights from `https://huggingface.co/vasudevgupta/tf-wav2vec2-base-960h` ... Done\n",
            "Total number of loaded variables: 213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxe1hATUMZ_Y"
      },
      "source": [
        "`processor` will help us to convert raw speech into required format which can be accepted into our `Wav2Vec2ForCTC` model. Eg: Normalizing the speech w.r.to frames axis.\n",
        "\n",
        "`tokenizer` will convert our model outputs into string and will take care of removal of special tokens (depending on your tokenizer configuration)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otRelAinM_Nw"
      },
      "source": [
        "For getting out of box performance with TensorFlow-2, we will be decorating our forward pass with `tf.function(...)`. Argument `jit_compile=True` will result in compilation of python code using **XLA** and will fuse operations to be able to generate very efficient code for accelerators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9AoBLfbQWXx"
      },
      "source": [
        "@tf.function(jit_compile=True)\n",
        "def tf_forward(speech, training=False):\n",
        "  tf_out = model(speech, training=training)\n",
        "  return tf.squeeze(tf.argmax(tf_out, axis=-1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6fMrDdZQWwy"
      },
      "source": [
        "It's time to write function for itertation over complete validation dataset. We will be collecting and storing predictions for each step in `list`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08-uHxommI6s"
      },
      "source": [
        "from data_utils import LibriSpeechDataLoader, LibriSpeechDataLoaderArgs\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def infer_librispeech(dataset: tf.data.Dataset):\n",
        "  predictions = []\n",
        "  labels = []\n",
        "  for batch in tqdm(dataset, total=len(dataset), desc=\"LibriSpeech Inference ... \"):\n",
        "    speech, label = batch\n",
        "    tf_out = tf_forward(speech, training=False)\n",
        "    predictions.extend([tokenizer.decode(pred, group_tokens=True) for pred in tf_out.numpy().tolist()])\n",
        "    labels.extend([tokenizer.decode(tgt, group_tokens=False) for tgt in label.numpy().tolist()])\n",
        "  return predictions, labels"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjosb9kiSuFj"
      },
      "source": [
        "Now, we will define the arguments for our `DataLoader` used in `infer_librispeech(...)` and will perform the inference on complete validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPT_W-8xOiKM",
        "outputId": "2fbc7804-b8be-44a7-bf75-3129d88b9edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "args = LibriSpeechDataLoaderArgs(data_dir=\"../data/LibriSpeech/test-clean\", batch_size=32, audio_maxlen=500000, labels_maxlen=256)\n",
        "\n",
        "dataset = LibriSpeechDataLoader(args)(seed=None)\n",
        "dataset = dataset.take(2) # this will take 2 batches"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DISCARDING 2 samples\n",
            "LOADED 2618 FILES FROM ../data/LibriSpeech/test-clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZNEtB3khu1l"
      },
      "source": [
        "Following cell will take ~ 7 mins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmvU-_otsGIG"
      },
      "source": [
        "predictions, labels = infer_librispeech(dataset)\n",
        "list(zip(predictions, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-5mtheUO3YP"
      },
      "source": [
        "It's time to calculate **Word Error Rate (WER)** to be able to judge if our model performed well. We will be using `load_metric(...)` function from HuggingFace datasets to setup metric for us. First, let's install `datasets` library using `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0paGBZEtO2SJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02cb1e9-e113-4974-8be5-fbc39750ed4c"
      },
      "source": [
        "!pip3 install datasets"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/a2/d4e1024c891506e1cee8f9d719d20831bac31cb5b7416983c4d2f65a6287/datasets-1.8.0-py3-none-any.whl (237kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.11)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, datasets\n",
            "Successfully installed datasets-1.8.0 fsspec-2021.6.1 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpejK25XO9AH"
      },
      "source": [
        "Let's install WER script using `load_metric(wer)` and compute metric value over our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRjHlsyytlnt"
      },
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "wer = load_metric(\"wer\")\n",
        "wer.compute(references=labels, predictions=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yv8ZF3P849v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}